{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb8c13c3-43ed-4df3-a394-9caba06a512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sas7bdat import SAS7BDAT\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal, chi2\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Define EM, Likelihood, TPR, etc\n",
    "def lrt(full_ll, reduced_ll, dof):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates likelihood ratio test statistic and p value for the two input loglikes\n",
    "    \n",
    "    Args:\n",
    "    - full_ll: float, full model log-likelihood\n",
    "    - reduced_ll: float, reduced model loglikelihood\n",
    "    - dof: degrees of freedom (n_full_params - n_reduced_params)\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    - lrt_stat: float, LRT test statistic\n",
    "    - p_value: float, unadjusted p-value for test-statistic\n",
    "    \"\"\"\n",
    "    \n",
    "    lrt_stat = -2 * (reduced_ll - full_ll)\n",
    "    p_value = chi2.sf(lrt_stat, df=dof)\n",
    "    \n",
    "    return lrt_stat, p_value\n",
    "\n",
    "def calc_tpr_fpr(lrt_results, threshold=0.05, solutions = solutions, FDR_BH=False):\n",
    "    \"\"\"\n",
    "    Takes in Likelihood Ratio Test result tuples, and provides FPR and TPR based on threshold and FDR control\n",
    "    \n",
    "    \"\"\"\n",
    "    FP = 0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    #Benjamini-Hochberg Procedure for FDR control\n",
    "    if FDR_BH:\n",
    "        \n",
    "        pvalues = np.array([t[2] for t in lrt_results])\n",
    "        genes = np.array([t[0] for t in lrt_results])\n",
    "        \n",
    "        m = len(pvalues)\n",
    "        \n",
    "        sorted_indices = np.argsort(pvalues)\n",
    "        sorted_pvalues = pvalues[sorted_indices]\n",
    "        sorted_genes = genes[sorted_indices]\n",
    "        \n",
    "        for i in range(m):\n",
    "            corrected_alpha = threshold * ((i + 1) / m)\n",
    "            \n",
    "            if sorted_genes[i] in solutions and sorted_pvalues[i] < corrected_alpha:\n",
    "                TP += 1\n",
    "            elif sorted_genes[i] in solutions and sorted_pvalues[i] >= corrected_alpha:\n",
    "                FN += 1\n",
    "            elif sorted_genes[i] not in solutions and sorted_pvalues[i] < corrected_alpha:\n",
    "                FP += 1\n",
    "            elif sorted_genes[i] not in solutions and sorted_pvalues[i] >= corrected_alpha:\n",
    "                TN += 1\n",
    "    \n",
    "    #Just compare against set alpha\n",
    "    else:\n",
    "        for i, result in enumerate(lrt_results):\n",
    "\n",
    "            if result[0] in solutions and result[2] < threshold:\n",
    "                TP += 1\n",
    "            elif result[0] in solutions and result[2] >= threshold:\n",
    "                FN += 1\n",
    "            elif result[0] not in solutions and result[2] < threshold:\n",
    "                FP += 1\n",
    "            elif result[0] not in solutions and result[2] >= threshold:\n",
    "                TN += 1\n",
    "\n",
    "    FPR = (FP)/(FP+TN)\n",
    "    TPR = (TP)/(TP+FN)\n",
    "    \n",
    "    \n",
    "    return TPR, FPR\n",
    "\n",
    "def likelihood_function_fix(y, X_fixed, beta, sigma2, alpha=2):\n",
    "    \"\"\"\n",
    "    Calculates the log-likelihood of a linear fixed effects model.\n",
    "    \n",
    "    Args:\n",
    "    - y: numpy array of shape (n,) (response variable)\n",
    "    - X_fixed: numpy array of shape (n,p), the design matrix for fixed effects\n",
    "    - \n",
    "    - beta: nump array of shape (p,), the fixed-effect coefficients\n",
    "    - sigma2: float, error variance\n",
    "    \n",
    "    Returns:\n",
    "    - loglik: float, the log-likelihood of the model given the input parameters\n",
    "    \"\"\"\n",
    "    #num obs\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    \n",
    "    #fixed effects (matrix mult of coeffs across fixed effects)\n",
    "    mu = X_fixed.dot(beta)\n",
    "    \n",
    "    \n",
    "    #total linear predictor\n",
    "    eta = mu \n",
    "    \n",
    "    #Expected value of complete data log-likelihood\n",
    "    \n",
    "    loglik = multivariate_normal.logpdf(y - eta, mean=np.zeros(n), cov=(sigma2*np.eye(n) + 1e-8*np.eye(n))).sum()\n",
    "    \n",
    "    #regularization penalty\n",
    "    reg_pen = alpha * np.sum(beta**2)\n",
    "    \n",
    "    loglik -= reg_pen\n",
    "    \n",
    "    \n",
    "    return loglik\n",
    "\n",
    "\n",
    "def EM_algorithm_fix(y, X_fixed, init_beta, init_sigma2, max_iter=200, tol=1e-7):\n",
    "    \"\"\"\n",
    "    Runs the EM algorithm to estimate the parameters of a linear mixed effects model\n",
    "    \n",
    "    Args:\n",
    "    - y: numpy array of shape (n,) (response variable)\n",
    "    - X_fixed: numpy array of shape (n,p), the design matrix for fixed effects\n",
    "    - \n",
    "    - init_beta: nump array of shape (p,), initial_estimate of the fixed-effect coefficients\n",
    "    - init_sigma2: float, error variance initial estimate\n",
    "    - max_iter: int, maximum iterations allowed before deciding the model won't converge\n",
    "    - tol: float, tolerance for convergence (if diff in improvement is too small, consider it converged)\n",
    "    \n",
    "    Returns:\n",
    "    - beta_hat: numpy array of shape (p,), estimate of fixed-effect coeffs\n",
    "    - sigma2_hat: float, the estimate of the error variance\n",
    "    \"\"\"\n",
    "    #init params\n",
    "    beta = init_beta\n",
    "    sigma2 = init_sigma2\n",
    "    \n",
    "    #Init loglike and convergence criteria\n",
    "    loglik = -np.inf\n",
    "    loglik_old = -np.inf\n",
    "    conv = False\n",
    "    iter_count = 0\n",
    "    \n",
    "    \n",
    "    #Begin the E step -> M step loop\n",
    "    while not(conv) and (iter_count < max_iter):\n",
    "        \n",
    "        # Big E Step\n",
    "        eta = X_fixed.dot(beta)\n",
    "        \n",
    "        loglik = likelihood_function_fix(y=y, X_fixed=X_fixed, beta=beta, sigma2=sigma2)\n",
    "        \n",
    "        \n",
    "        #And for the M step\n",
    "        beta_new = np.linalg.inv(X_fixed.T.dot(X_fixed)).dot(X_fixed.T).dot(y)\n",
    "        \n",
    "        sigma2_new = np.mean((y - eta)**2)\n",
    "        \n",
    "        #update params\n",
    "        beta = beta_new\n",
    "        \n",
    "        sigma2 = sigma2_new\n",
    "        \n",
    "        #Check convergence\n",
    "        if np.abs(loglik - loglik_old) < tol:\n",
    "            conv = True\n",
    "            print(f\"                          Model converged on iteration {iter_count}\", end = \"\\r\")\n",
    "        \n",
    "        loglik_old = loglik\n",
    "        iter_count += 1\n",
    "        \n",
    "    \n",
    "    return beta, sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6182147-8bcc-4fc0-bd78-70ff49dd620e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x2', 'x4', 'x5'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Define number of observations and fixed effect variables\n",
    "n_obs = 1000\n",
    "n_vars = 5\n",
    "\n",
    "# Generate fixed effect variables\n",
    "x = np.random.normal(size=(n_obs, n_vars))\n",
    "\n",
    "# Generate random coefficients for fixed effect variables\n",
    "beta = np.random.normal(size=n_vars)\n",
    "\n",
    "# Randomly select some variables to have coefficient of 0\n",
    "zero_vars = np.random.choice(n_vars, size=int(n_vars/2), replace=False)\n",
    "beta[zero_vars] = 0\n",
    "\n",
    "# Generate error term\n",
    "error = np.random.normal(scale=0.5, size=n_obs)\n",
    "\n",
    "# Generate response variable\n",
    "y = np.dot(x, beta) + error\n",
    "\n",
    "# Permute response variable\n",
    "y_perm = np.random.permutation(y)\n",
    "\n",
    "# Normalize fixed effect variables\n",
    "scaler = StandardScaler()\n",
    "x_norm = scaler.fit_transform(x)\n",
    "\n",
    "# Combine into a dataframe\n",
    "df = pd.DataFrame(np.hstack((y_perm.reshape(-1, 1), x_norm)), columns=['y'] + [f'x{i+1}' for i in range(n_vars)])\n",
    "\n",
    "# Get solution indices of true model\n",
    "solutions = np.where(beta != 0)\n",
    "\n",
    "varlist = np.array(df.drop(['y'], axis=1).columns)\n",
    "varlist\n",
    "solutions = set(varlist[solutions])\n",
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12a862-313e-4b62-b675-662d5001ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuation 1:             Model converged on iteration 3\n",
      "Model (-var x5):          Model converged on iteration 3\r"
     ]
    }
   ],
   "source": [
    "\n",
    "nperms = 10\n",
    "first_pass = True\n",
    "sigma2 = 0\n",
    "roc_data = [[0],[0]]\n",
    "lrt_results_lst = []\n",
    "\n",
    "for perm in range(nperms):\n",
    "    y_perm = np.random.permutation(y)\n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((y_perm.reshape(-1, 1), x_norm)), columns=['y'] + [f'x{i+1}' for i in range(n_vars)])\n",
    "    \n",
    "\n",
    "    fixed_ = df.drop(['y'], axis = 1).to_numpy()\n",
    "    y = df['y'].to_numpy()\n",
    "    \n",
    "    p = fixed_.shape[1]\n",
    "    \n",
    "    #Recycle any params? probably no\n",
    "    if first_pass:\n",
    "        sigma2 = np.var(y)\n",
    "        beta = np.zeros(p)\n",
    "        first_pass = False\n",
    "        \n",
    "    else:\n",
    "        sigma2 = np.var(y)\n",
    "        beta = np.zeros(p)\n",
    "\n",
    "    beta, sigma2 = EM_algorithm_fix(y, fixed_, beta, sigma2, max_iter=200, tol=1e-7)\n",
    "    \n",
    "    print(f\"Permuation {perm+1}:\")\n",
    "    \n",
    "    full_ll = likelihood_function_fix(y, fixed_, beta, sigma2)\n",
    "    \n",
    "    lrt_results = []\n",
    "\n",
    "    for j, var in enumerate(varlist):\n",
    "        \n",
    "        reduced_fixed = df.drop([var], axis =1).to_numpy()\n",
    "        \n",
    "        p_r = reduced_fixed.shape[1]\n",
    "        \n",
    "        reduced_beta = np.zeros(p_r)\n",
    "        \n",
    "        r_sigma2 = np.var(y)\n",
    "        \n",
    "        r_beta, r_sigma2 = EM_algorithm_fix(y, reduced_fixed, reduced_beta, sigma2, max_iter=200, tol=1e-7)\n",
    "        \n",
    "        print(f\"Model (-var {var}):\", end=\"\\r\")\n",
    "        \n",
    "        reduced_ll = likelihood_function_fix(y, reduced_fixed, reduced_beta, r_sigma2)\n",
    "        \n",
    "        lrt_result = lrt(full_ll, reduced_ll, dof=1)\n",
    "        \n",
    "        lrt_results.append((var, lrt_result[0], lrt_result[1]))\n",
    "    \n",
    "    \n",
    "    TPR, FPR = calc_tpr_fpr(lrt_results,threshold=(0.05/(fixed_.shape[1]*nperms)), FDR_BH=False, solutions=solutions)\n",
    "    roc_data[0].append(TPR)\n",
    "    roc_data[1].append(FPR)\n",
    "    lrt_results_lst.append(lrt_results)\n",
    "    \n",
    "print(\"\\r\\ndone\")\n",
    "\n",
    "fpr = np.array(roc_data[1])\n",
    "tpr = np.array(roc_data[0])\n",
    "\n",
    "sorted_indices = np.argsort(fpr)\n",
    "fpr = fpr[sorted_indices]\n",
    "tpr = tpr[sorted_indices]\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0,1],[0,1], linestyle='--', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83ff41a4-3973-4edf-9d43-dcbae37c72da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('x1', 414058294097.2899, 0.0),\n",
       "  ('x2', 414058294097.2899, 0.0),\n",
       "  ('x3', 414058294097.2899, 0.0),\n",
       "  ('x4', 414058294097.2899, 0.0),\n",
       "  ('x5', 414058294097.2899, 0.0)],\n",
       " [('x1', 414058294095.55444, 0.0),\n",
       "  ('x2', 414058294095.55444, 0.0),\n",
       "  ('x3', 414058294095.55444, 0.0),\n",
       "  ('x4', 414058294095.55444, 0.0),\n",
       "  ('x5', 414058294095.55444, 0.0)],\n",
       " [('x1', 414058294099.8011, 0.0),\n",
       "  ('x2', 414058294099.8011, 0.0),\n",
       "  ('x3', 414058294099.8011, 0.0),\n",
       "  ('x4', 414058294099.8011, 0.0),\n",
       "  ('x5', 414058294099.8011, 0.0)],\n",
       " [('x1', 414058294105.6701, 0.0),\n",
       "  ('x2', 414058294105.6701, 0.0),\n",
       "  ('x3', 414058294105.6701, 0.0),\n",
       "  ('x4', 414058294105.6701, 0.0),\n",
       "  ('x5', 414058294105.6701, 0.0)],\n",
       " [('x1', 414058294099.3615, 0.0),\n",
       "  ('x2', 414058294099.3615, 0.0),\n",
       "  ('x3', 414058294099.3615, 0.0),\n",
       "  ('x4', 414058294099.3615, 0.0),\n",
       "  ('x5', 414058294099.3615, 0.0)],\n",
       " [('x1', 414058294094.9897, 0.0),\n",
       "  ('x2', 414058294094.9897, 0.0),\n",
       "  ('x3', 414058294094.9897, 0.0),\n",
       "  ('x4', 414058294094.9897, 0.0),\n",
       "  ('x5', 414058294094.9897, 0.0)],\n",
       " [('x1', 414058294100.44464, 0.0),\n",
       "  ('x2', 414058294100.44464, 0.0),\n",
       "  ('x3', 414058294100.44464, 0.0),\n",
       "  ('x4', 414058294100.44464, 0.0),\n",
       "  ('x5', 414058294100.44464, 0.0)],\n",
       " [('x1', 414058294095.7439, 0.0),\n",
       "  ('x2', 414058294095.7439, 0.0),\n",
       "  ('x3', 414058294095.7439, 0.0),\n",
       "  ('x4', 414058294095.7439, 0.0),\n",
       "  ('x5', 414058294095.7439, 0.0)],\n",
       " [('x1', 414058294099.8812, 0.0),\n",
       "  ('x2', 414058294099.8812, 0.0),\n",
       "  ('x3', 414058294099.8812, 0.0),\n",
       "  ('x4', 414058294099.8812, 0.0),\n",
       "  ('x5', 414058294099.8812, 0.0)],\n",
       " [('x1', 414058294097.279, 0.0),\n",
       "  ('x2', 414058294097.279, 0.0),\n",
       "  ('x3', 414058294097.279, 0.0),\n",
       "  ('x4', 414058294097.279, 0.0),\n",
       "  ('x5', 414058294097.279, 0.0)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_results_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ec3a1-1424-4832-a537-2ef811f71217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
